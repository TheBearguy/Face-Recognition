{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmTecFbpx3VD",
        "outputId": "4fff1dd7-4c34-4745-edf7-e6c13a5e0bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymdptoolbox\n",
            "  Downloading pymdptoolbox-4.0-b3.zip (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pymdptoolbox) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pymdptoolbox) (1.10.1)\n",
            "Building wheels for collected packages: pymdptoolbox\n",
            "  Building wheel for pymdptoolbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymdptoolbox: filename=pymdptoolbox-4.0b3-py3-none-any.whl size=25656 sha256=4c2f84b85d54f10789e9b64846e6e15e14bb7ab214db38dfa65e180ec5406d2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/e7/c7/d7abf9e309f3573a934fed2750c70bd75d9e9d901f7f16e183\n",
            "Successfully built pymdptoolbox\n",
            "Installing collected packages: pymdptoolbox\n",
            "Successfully installed pymdptoolbox-4.0b3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymdptoolbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mdptoolbox.example\n",
        "import mdptoolbox.mdp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wNSVad1fyWBd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs\n",
        "'''\n",
        "    S  : is the number of states (in this example, the different possible ages of the forest)\n",
        "    r1 : is the reward that you get when you 'wait' and the forest is in its oldest state\n",
        "    r2 : is the reward that you get when you 'cut' the trees and the forest is in its oldest state\n",
        "    p  : is the probability of a wildfire occurrence\n",
        "'''\n",
        "\n",
        "# outputs\n",
        "'''\n",
        "    P : the transition probability matrix, a numpy array of shape (A, S, S) where A is the possible actions\n",
        "    and S is the possible states\n",
        "\n",
        "    R : the reward matrix of shape (S, A)\n",
        "'''\n",
        "P, R = mdptoolbox.example.forest(S=3, r1=4, r2=2, p=0.1, is_sparse=False)"
      ],
      "metadata": {
        "id": "wOBJUNZLy1KN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuR6qUvBzSNd",
        "outputId": "46fa52f0-6d26-40e8-a97d-6d0d6e04a5f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1, 0.9, 0. ],\n",
              "        [0.1, 0. , 0.9],\n",
              "        [0.1, 0. , 0.9]],\n",
              "\n",
              "       [[1. , 0. , 0. ],\n",
              "        [1. , 0. , 0. ],\n",
              "        [1. , 0. , 0. ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P[0] # this is the probability transition matrix if the action 'wait' is chosen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWJGXVS7zVsP",
        "outputId": "291de309-a6c7-4b76-8f2b-47f01ec22713"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1, 0.9, 0. ],\n",
              "       [0.1, 0. , 0.9],\n",
              "       [0.1, 0. , 0.9]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ex: what is the probability that a forest in its youngest state\n",
        " will advance to the next oldest, if we wait?\n",
        "'''\n",
        "print(P[0][0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7IcvbXNzeJS",
        "outputId": "ee33557e-2336-43bf-e9c9-ead37884747b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ex: what is the probability that a forest in its oldest state\n",
        " will burn down, if we wait?\n",
        "'''\n",
        "print(P[0][2][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aht76nY7zw7x",
        "outputId": "eb614f64-3882-4417-b5f2-ed1b19817914"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the rewards matrix. Rewards matrix has shape S x A (S,A)."
      ],
      "metadata": {
        "id": "pxLkG2-s0Lzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EjTvl400JIJ",
        "outputId": "5d963da7-7d9a-4b7a-f073-3e87afbc3c5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 1.],\n",
              "       [4., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what reward do we get if we choose to wait, and the forest is in its oldest state?\n",
        "np.sum(R.T[0]*[0, 0, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekZJo7Mm0OJH",
        "outputId": "8d45c1f6-a7ff-4944-d12f-882aba4f8edd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what reward do we get if we choose to wait, and the forest is in any other state?\n",
        "np.sum(np.multiply(R.T[0], [1, 1, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTb9iIEh0XV9",
        "outputId": "40bbbeaf-f5d2-4f6d-9a04-7744becb717a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what reward do we get if we choose to cut, and the forest is in its oldest state?\n",
        "np.sum(np.multiply(R.T[1], [0, 0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG1CWaH30aXk",
        "outputId": "5e757534-0550-472c-ee7f-530b5cac6f67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what reward do we get if we choose to cut, and the forest is in its second youngest state?\n",
        "np.sum(np.multiply(R.T[1], [0, 1, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L5Y3W800cFs",
        "outputId": "a9376ad5-c239-44a7-82d9-29e575fc5f91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the optimal \"policy\""
      ],
      "metadata": {
        "id": "D2XEeoSS0nZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = mdptoolbox.mdp.QLearning(P, R, discount = 0.1)\n",
        "model.run()\n",
        "model.policy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M9DwN_O0jei",
        "outputId": "59ddea94-11b3-42d6-92ba-24c5fee4cd40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should we wait (0) or cut (1) in the youngest state?\n",
        "model.policy[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me32Eh7X0qa9",
        "outputId": "449ba60c-492a-43e9-d8f7-587ddeafb250"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should we wait (0) or cut (1) in the second youngest state?\n",
        "model.policy[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFP55Wp-0tED",
        "outputId": "62992865-7227-424d-8d64-a301f0d8f264"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# should we wait (0) or cut (1) in the oldest state?\n",
        "model.policy[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snmp-JXJ0ueN",
        "outputId": "a9b00baa-5bce-4707-daa3-1cca17282da2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#applying a discount to our model.\n",
        "(what is a discount?)"
      ],
      "metadata": {
        "id": "1zqG9xiX8Fe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 99% discount says that it is very likely that the scenario will continue into the future (long-term strategy)\n",
        "model = mdptoolbox.mdp.QLearning(P, R, discount = 0.99)\n",
        "model.run()\n",
        "model.policy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_krZdlre0v0f",
        "outputId": "882b16cd-959c-41f5-b1f0-bf277fcdc6c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1% discount says that it is very likely the scenario will not continue in the future (short-term)\n",
        "model = mdptoolbox.mdp.QLearning(P, R, discount = 0.5)\n",
        "model.run()\n",
        "model.policy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFplJk5e8IRc",
        "outputId": "820b39ca-514d-4cbc-9721-ada979287076"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mdptoolbox.example.rand(S = 5, A = 4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guwZgp428Kp1",
        "outputId": "5fd11a8a-9e21-4ea4-9da7-360f71194c85"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.        , 0.        , 0.        , 1.        , 0.        ],\n",
              "         [0.62171401, 0.        , 0.        , 0.37828599, 0.        ],\n",
              "         [0.26954371, 0.53876999, 0.        , 0.        , 0.19168631],\n",
              "         [0.        , 0.        , 1.        , 0.        , 0.        ],\n",
              "         [0.10068004, 0.37400855, 0.3819096 , 0.04990294, 0.09349887]],\n",
              " \n",
              "        [[0.28870937, 0.31474932, 0.        , 0.        , 0.39654131],\n",
              "         [0.        , 0.        , 0.        , 0.        , 1.        ],\n",
              "         [0.0970911 , 0.34278019, 0.        , 0.16673506, 0.39339366],\n",
              "         [0.26739848, 0.        , 0.33516087, 0.02771253, 0.36972812],\n",
              "         [0.        , 0.        , 1.        , 0.        , 0.        ]],\n",
              " \n",
              "        [[0.        , 0.02094889, 0.        , 0.97905111, 0.        ],\n",
              "         [0.20911959, 0.1292207 , 0.1318295 , 0.21160817, 0.31822205],\n",
              "         [0.34537801, 0.59211727, 0.06250472, 0.        , 0.        ],\n",
              "         [0.15981692, 0.37394382, 0.3073153 , 0.10140783, 0.05751614],\n",
              "         [0.37284896, 0.        , 0.09011649, 0.        , 0.53703455]],\n",
              " \n",
              "        [[0.        , 0.        , 1.        , 0.        , 0.        ],\n",
              "         [0.09251278, 0.50047507, 0.        , 0.        , 0.40701215],\n",
              "         [0.        , 0.28639401, 0.31422549, 0.32526115, 0.07411935],\n",
              "         [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
              "         [0.13768766, 0.26385375, 0.02265089, 0.20908762, 0.36672009]]]),\n",
              " array([[[-0.        , -0.        , -0.        ,  0.1703855 ,\n",
              "           0.        ],\n",
              "         [-0.41788828, -0.        , -0.        ,  0.15494564,\n",
              "           0.        ],\n",
              "         [-0.45411182, -0.72219215,  0.        ,  0.        ,\n",
              "           0.7509677 ],\n",
              "         [ 0.        ,  0.        ,  0.67053257,  0.        ,\n",
              "          -0.        ],\n",
              "         [-0.38843992, -0.2749754 , -0.80401278,  0.99166685,\n",
              "          -0.11196118]],\n",
              " \n",
              "        [[-0.31472615,  0.57460663, -0.        ,  0.        ,\n",
              "          -0.87088493],\n",
              "         [-0.        ,  0.        , -0.        , -0.        ,\n",
              "          -0.05080156],\n",
              "         [-0.34474215, -0.45020785,  0.        , -0.57280698,\n",
              "          -0.59580482],\n",
              "         [-0.97046985, -0.        , -0.02559183, -0.04736414,\n",
              "          -0.46531339],\n",
              "         [ 0.        , -0.        , -0.22829987, -0.        ,\n",
              "           0.        ]],\n",
              " \n",
              "        [[-0.        ,  0.62257061,  0.        , -0.63407502,\n",
              "          -0.        ],\n",
              "         [ 0.5914957 , -0.75811361,  0.4358019 ,  0.9838574 ,\n",
              "           0.69282627],\n",
              "         [-0.7656494 ,  0.40876358,  0.53234734,  0.        ,\n",
              "          -0.        ],\n",
              "         [ 0.10968218, -0.78714335,  0.30180877,  0.1319382 ,\n",
              "          -0.89725623],\n",
              "         [-0.20389749, -0.        ,  0.06338944,  0.        ,\n",
              "           0.55066696]],\n",
              " \n",
              "        [[ 0.        ,  0.        ,  0.30813829, -0.        ,\n",
              "           0.        ],\n",
              "         [-0.39654628,  0.20009535, -0.        ,  0.        ,\n",
              "          -0.71928845],\n",
              "         [-0.        , -0.99926838, -0.51185717, -0.04100006,\n",
              "           0.6078116 ],\n",
              "         [-0.        , -0.        , -0.        ,  0.51586683,\n",
              "          -0.        ],\n",
              "         [-0.23632332,  0.29263464,  0.4373981 , -0.67709996,\n",
              "          -0.29690495]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ec_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "WOIEj3OK8M3h",
        "outputId": "43a32183-6744-462c-fd8b-6ab0db9104d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-223a399e4933>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mec_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ec_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvpOMpiD8O7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}